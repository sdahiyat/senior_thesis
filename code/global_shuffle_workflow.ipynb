{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed774cd4-8f46-4a99-bf5c-b0481dbe394d",
   "metadata": {},
   "source": [
    "## Codon and Motif Shuffle Reproducibility Workflow\n",
    "This notebook documents the process of generating new sequence datasets for testing SpliceAI.\n",
    "\n",
    "Objective\n",
    "To investigate how SpliceAI relies on different sequence features (e.g., nucleotide structure, codon structure), we:\n",
    "\n",
    "Shuffle nucleotide sequences in different ways\n",
    "Preserve structures like splice junctions\n",
    "Generate perturbed versions of the original transcriptome\n",
    "Workflow Overview\n",
    "1. Load Canonical Transcript Dataset\n",
    "Read exon/intron boundaries from canonical .bed files\n",
    "Extract corresponding sequences from a reference FASTA\n",
    "2. Apply Shuffling Strategies\n",
    "Nucleotide Shuffle: Randomize exon sequences fully (baseline destruction)\n",
    "Codon Shuffle: Shuffle only within codon triplets, preserving reading frame\n",
    "3. Reconstruct FASTA Files\n",
    "Replace original sequences with shuffled versions\n",
    "Ensure intron/exon structure and transcript orientation is preserved\n",
    "4. Write New Datasets\n",
    "Save to FASTA, BED, or HDF5 files for SpliceAI input\n",
    "Include aligned inputs for comparative testing\n",
    "Outputs\n",
    "Shuffled FASTA files for input to SpliceAI as the 'splice table' argument\n",
    "This notebook serves as documentation for dataset perturbation and reproducibility of the shuffling experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d741c3-1f31-4b35-9893-ce38ab43a0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "reference_genome_path = \"/mnt/lareaulab/sdahiyat/hg19.fa\" # my reference genome\n",
    "canonical_dataset_path = \"/mnt/lareaulab/sdahiyat/illumina/canonical_dataset_created.txt\"\n",
    "output_file_path = \"/mnt/lareaulab/sdahiyat/illumina/canonical_sequence_unflanked_unshuffled.txt\"\n",
    "\n",
    "# Open the reference genome\n",
    "reference_genome = pysam.FastaFile(reference_genome_path)\n",
    "\n",
    "# Load canonical dataset\n",
    "canonical_df = pd.read_csv(\n",
    "    canonical_dataset_path,\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"geneName\", \"chrom\", \"strand\", \"chromStart\", \"chromEnd\", \"exonEnds\", \"exonStarts\"]\n",
    ")\n",
    "\n",
    "# Create the canonical sequence file **without flanked 'N's**\n",
    "with open(output_file_path, \"w\") as output_file:\n",
    "    for _, row in canonical_df.iterrows():\n",
    "        chrom = row[\"chrom\"]\n",
    "        chrom_start = row[\"chromStart\"]\n",
    "        chrom_end = row[\"chromEnd\"]\n",
    "        strand = row[\"strand\"]\n",
    "\n",
    "        # Fetch the **exact** sequence without adding flanks\n",
    "        core_sequence = reference_genome.fetch(chrom, chrom_start-1, chrom_end)  # 0-based index\n",
    "\n",
    "        # Reverse complement if on the negative strand\n",
    "        if strand == \"-\":\n",
    "            core_sequence = core_sequence.translate(str.maketrans(\"ATCG\", \"TAGC\"))[::-1]\n",
    "\n",
    "        # Write to output file with canonical transcript ID\n",
    "        output_file.write(f\"{chrom}:{chrom_start}-{chrom_end}\\t{core_sequence}\\n\")\n",
    "\n",
    "print(f\" Canonical sequence file created at {output_file_path} (without flanking 'N's)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d67b2f3-97e7-4a34-ade0-e18b3e12c275",
   "metadata": {},
   "source": [
    "## calculate nucleotide frequencies of intron sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fa9cfc-8327-47f0-9e55-fc77449e5eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "valid_nucleotides = {\"A\", \"C\", \"G\", \"T\"} \n",
    "input_file = \"extracted_intron_sequences.txt\" # separate file of just intron sequences\n",
    "nucleotide_counts = Counter()\n",
    "\n",
    "with open(input_file, \"r\") as file:\n",
    "    for line in file:\n",
    "        if not line.startswith(\">\"): \n",
    "            sequence = [char for char in line.strip().upper() if char in valid_nucleotides]\n",
    "            nucleotide_counts.update(sequence)\n",
    "\n",
    "total_bases = sum(count for base, count in nucleotide_counts.items() if base != \"N\")\n",
    "\n",
    "frequencies = {base: count / total_bases for base, count in nucleotide_counts.items() if base != \"N\"}\n",
    "print(\"Nucleotide Frequencies (excluding N):\")\n",
    "for base, freq in sorted(frequencies.items()):\n",
    "    print(f\"{base}: {freq:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6034b83-7aaf-4043-a197-9b6169275237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Define nucleotide frequencies\n",
    "nucleotide_frequencies = {\n",
    "    \"A\": 0.2781,\n",
    "    \"C\": 0.2025,\n",
    "    \"G\": 0.2120,\n",
    "    \"T\": 0.3075\n",
    "}\n",
    "nucleotides = list(nucleotide_frequencies.keys())\n",
    "weights = list(nucleotide_frequencies.values())\n",
    "\n",
    "def generate_random_sequence(length):\n",
    "    return ''.join(random.choices(nucleotides, weights=weights, k=length))\n",
    "\n",
    "def shuffle_sequences(canonical_sequences_file, output_file, junctions):\n",
    "    with open(canonical_sequences_file, \"r\") as infile, open(output_file, \"w\") as outfile:\n",
    "        for line in infile:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                header, sequence = line.split(\"\\t\")\n",
    "            except ValueError:\n",
    "                print(f\"Skipping malformed line: {line}\")\n",
    "                continue\n",
    "\n",
    "            transcript_key = header\n",
    "\n",
    "            if transcript_key in junctions:\n",
    "                seq_start = int(transcript_key.split(\":\")[1].split(\"-\")[0])\n",
    "                adjusted_junctions = [\n",
    "                    (start - seq_start, end - seq_start)\n",
    "                    for start, end in junctions[transcript_key]\n",
    "                ]\n",
    "\n",
    "                exons_introns = []\n",
    "                last_pos = 0\n",
    "                for exon_start, exon_end in adjusted_junctions:\n",
    "                    exons_introns.append(sequence[last_pos:exon_start])\n",
    "\n",
    "                    # Shuffle exon\n",
    "                    exon_length = exon_end - exon_start\n",
    "                    fake_exon = generate_random_sequence(exon_length)\n",
    "                    exons_introns.append(fake_exon)\n",
    "\n",
    "                    last_pos = exon_end\n",
    "\n",
    "                exons_introns.append(sequence[last_pos:])  \n",
    "                shuffled_sequence = ''.join(exons_introns)\n",
    "            else:\n",
    "                shuffled_sequence = generate_random_sequence(len(sequence))\n",
    "\n",
    "            outfile.write(f\"{header}\\t{shuffled_sequence}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "canonical_dataset_path = \"/mnt/lareaulab/sdahiyat/illumina/canonical_dataset_created.txt\"\n",
    "canonical_sequences_file = \"/mnt/lareaulab/sdahiyat/illumina/canonical_sequence_unflanked_unshuffled.txt\"\n",
    "output_file_path = \"/mnt/lareaulab/sdahiyat/illumina/shuffled_nt_new.txt\"\n",
    "\n",
    "junctions = parse_junctions(canonical_dataset_path)\n",
    "\n",
    "shuffle_sequences(canonical_sequences_file, output_file_path, junctions)\n",
    "\n",
    "print(f\"Shuffled sequences written to {output_file_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f335f1-bffd-4477-a327-d4ecea97068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"/mnt/lareaulab/sdahiyat/illumina/shuffled_nt_new.txt\"\n",
    "output_file = \"/mnt/lareaulab/sdahiyat/illumina/flanked_shuffled_nt.txt\"\n",
    "\n",
    "# Define the flanking sequence (5000 Ns)\n",
    "flank_length = 5000\n",
    "flanking_seq = \"N\" * flank_length\n",
    "\n",
    "# Process the input file and write the modified sequences to output\n",
    "with open(input_file, \"r\") as infile, open(output_file, \"w\") as outfile:\n",
    "    for line in infile:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  # Skip empty lines\n",
    "        \n",
    "        try:\n",
    "            header, sequence = line.split(\"\\t\")\n",
    "        except ValueError:\n",
    "            print(f\"Skipping malformed line: {line}\")\n",
    "            continue\n",
    "        \n",
    "        # Extract chromosome, start, and end positions\n",
    "        if \":\" in header and \"-\" in header:\n",
    "            chrom, positions = header.split(\":\")\n",
    "            start, end = map(int, positions.split(\"-\"))\n",
    "            \n",
    "            # Adjust start and end positions\n",
    "            new_start = start - 5001 \n",
    "            new_end = end + 5000\n",
    "            \n",
    "            # Construct new header\n",
    "            new_header = f\"{chrom}:{new_start}-{new_end}\"\n",
    "            \n",
    "            # Construct new sequence with flanking Ns\n",
    "            flanked_sequence = flanking_seq + sequence + flanking_seq\n",
    "            \n",
    "            # Write to output file\n",
    "            outfile.write(f\"{new_header}\\t{flanked_sequence}\\n\")\n",
    "        else:\n",
    "            print(f\"Skipping improperly formatted header: {header}\")\n",
    "\n",
    "print(f\"Flanked sequences written to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ac54e7-04f6-48e2-9307-bfe623eabab5",
   "metadata": {},
   "source": [
    "## Codon Shuffling Pipeline Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90fd65a-69d4-43ac-a381-a89f49a7d9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "def parse_junctions(file_path):\n",
    "    junctions = {}\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line_number, line in enumerate(f, start=1):\n",
    "            fields = line.strip().split(\"\\t\")\n",
    "            if len(fields) < 8:\n",
    "                continue\n",
    "\n",
    "            chrom = fields[2]\n",
    "            try:\n",
    "                start = int(fields[4])\n",
    "                end = int(fields[5])\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                exon_starts = list(map(int, fields[6].split(\",\")))\n",
    "                exon_ends = list(map(int, fields[7].split(\",\")))\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "            if len(exon_starts) != len(exon_ends):\n",
    "                continue\n",
    "\n",
    "            transcript_key = f\"{chrom}:{start}-{end}\"\n",
    "            junctions[transcript_key] = list(zip(exon_starts, exon_ends))\n",
    "    return junctions\n",
    "\n",
    "def load_sequences(file_path):\n",
    "    sequences = {}\n",
    "    with open(file_path, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                header, sequence = line.split(\"\\t\")\n",
    "                sequences[header] = sequence\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return sequences\n",
    "\n",
    "# compute global codon frequencies from all exons\n",
    "def compute_global_codon_frequencies(sequences, junctions):\n",
    "    codon_list = []\n",
    "    for transcript_key in sequences:\n",
    "        if transcript_key not in junctions:\n",
    "            continue\n",
    "        seq = sequences[transcript_key]\n",
    "        seq_start = int(transcript_key.split(\":\")[1].split(\"-\")[0])\n",
    "        for start, end in junctions[transcript_key]:\n",
    "            start_rel = start - seq_start\n",
    "            end_rel = end - seq_start\n",
    "            exon = seq[start_rel:end_rel].upper()\n",
    "            codon_list.extend([\n",
    "                exon[i:i+3] for i in range(0, len(exon) - 2, 3)\n",
    "                if len(exon[i:i+3]) == 3 and all(c in \"ACGT\" for c in exon[i:i+3])\n",
    "            ])\n",
    "    codon_counts = Counter(codon_list)\n",
    "    total = sum(codon_counts.values())\n",
    "    return list(codon_counts.keys()), [codon_counts[c] / total for c in codon_counts]\n",
    "\n",
    "# generate shuffled exon by sampling codons\n",
    "def generate_shuffled_exon(length, codons, weights):\n",
    "    if length <= 0:\n",
    "        return \"\"\n",
    "    num_codons = length // 3\n",
    "    shuffled = ''.join(random.choices(codons, weights=weights, k=num_codons))\n",
    "    remainder = length % 3\n",
    "    if remainder > 0:\n",
    "        shuffled += ''.join(random.choices(\"ACGT\", k=remainder))\n",
    "    return shuffled\n",
    "\n",
    "# shuffle while preserving introns \n",
    "def shuffle_sequences(canonical_sequences_file, output_file, junctions, codons, weights):\n",
    "    with open(canonical_sequences_file, \"r\") as infile, open(output_file, \"w\") as outfile:\n",
    "        for line in infile:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                header, sequence = line.split(\"\\t\")\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "            transcript_key = header\n",
    "\n",
    "            if transcript_key in junctions:\n",
    "                seq_start = int(transcript_key.split(\":\")[1].split(\"-\")[0])\n",
    "                adjusted_junctions = [\n",
    "                    (start - seq_start, end - seq_start)\n",
    "                    for start, end in junctions[transcript_key]\n",
    "                ]\n",
    "\n",
    "                exons_introns = []\n",
    "                last_pos = 0\n",
    "                for exon_start, exon_end in adjusted_junctions:\n",
    "                    exons_introns.append(sequence[last_pos:exon_start])\n",
    "                    exon_len = exon_end - exon_start\n",
    "                    shuffled_exon = generate_shuffled_exon(exon_len, codons, weights)\n",
    "                    exons_introns.append(shuffled_exon)\n",
    "                    last_pos = exon_end\n",
    "\n",
    "                exons_introns.append(sequence[last_pos:])\n",
    "                shuffled_sequence = ''.join(exons_introns)\n",
    "            else:\n",
    "                shuffled_sequence = generate_shuffled_exon(len(sequence), codons, weights)\n",
    "\n",
    "            outfile.write(f\"{transcript_key}\\t{shuffled_sequence}\\n\")\n",
    "\n",
    "canonical_dataset_path = \"/mnt/lareaulab/sdahiyat/illumina/canonical_dataset_created.txt\"\n",
    "canonical_sequences_file = \"/mnt/lareaulab/sdahiyat/illumina/canonical_sequence_unflanked_unshuffled.txt\"\n",
    "output_file_path = \"/mnt/lareaulab/sdahiyat/illumina/shuffled_codons_from_codon_freq.txt\"\n",
    "\n",
    "#main pipeline \n",
    "junctions = parse_junctions(canonical_dataset_path)\n",
    "sequences = load_sequences(canonical_sequences_file)\n",
    "codons, weights = compute_global_codon_frequencies(sequences, junctions)\n",
    "\n",
    "print(f\"Parsed {len(junctions)} junctions and {len(sequences)} sequences\")\n",
    "print(f\"Shuffling using {len(codons)} codons\")\n",
    "shuffle_sequences(canonical_sequences_file, output_file_path, junctions, codons, weights)\n",
    "print(f\"Shuffled sequences written to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a302cea6-cf0a-46bc-8d47-4f502cf832c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"/mnt/lareaulab/sdahiyat/illumina/shuffled_codons_from_codon_freq.txt\"\n",
    "output_file = \"/mnt/lareaulab/sdahiyat/illumina/flanked_shuffled_codons_423version.txt\"\n",
    "\n",
    "# define the flanking sequence of 5000 Ns\n",
    "flank_length = 5000\n",
    "flanking_seq = \"N\" * flank_length\n",
    "\n",
    "with open(input_file, \"r\") as infile, open(output_file, \"w\") as outfile:\n",
    "    for line in infile:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  \n",
    "        \n",
    "        try:\n",
    "            header, sequence = line.split(\"\\t\")\n",
    "        except ValueError:\n",
    "            print(f\"Skipping malformed line: {line}\")\n",
    "            continue\n",
    "        \n",
    "        # Extract chromosome, start, and end positions\n",
    "        if \":\" in header and \"-\" in header:\n",
    "            chrom, positions = header.split(\":\")\n",
    "            start, end = map(int, positions.split(\"-\"))\n",
    "            \n",
    "            # Adjust start and end positions\n",
    "            new_start = start - 5001 \n",
    "            new_end = end + 5000\n",
    "            \n",
    "            new_header = f\"{chrom}:{new_start}-{new_end}\"\n",
    "            \n",
    "            flanked_sequence = flanking_seq + sequence + flanking_seq\n",
    "            \n",
    "            outfile.write(f\"{new_header}\\t{flanked_sequence}\\n\")\n",
    "        else:\n",
    "            print(f\"Skipping improperly formatted header: {header}\")\n",
    "\n",
    "print(f\"Flanked sequences written to {output_file}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (september)",
   "language": "python",
   "name": "september"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
