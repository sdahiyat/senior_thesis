{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17088b71-a2ed-4027-b69e-296e5863ce28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled sequences written to /mnt/lareaulab/sdahiyat/illumina/shuffled_codons_2.txt.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "def parse_junctions(file_path):\n",
    "    junctions = {}\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line_number, line in enumerate(f, start=1):\n",
    "            fields = line.strip().split(\"\\t\")\n",
    "            \n",
    "            if len(fields) < 6:\n",
    "                print(f\"Skipping invalid row at line {line_number}: {line.strip()}\")\n",
    "                continue\n",
    "            \n",
    "            chrom = fields[2]\n",
    "            try:\n",
    "                start = int(fields[4])\n",
    "                end = int(fields[5])\n",
    "            except ValueError:\n",
    "                print(f\"Skipping row with invalid start/end at line {line_number}: {line.strip()}\")\n",
    "                continue\n",
    "\n",
    "            exon_starts = []\n",
    "            exon_ends = []\n",
    "            if len(fields) >= 8:\n",
    "                try:\n",
    "                    exon_starts = list(map(int, fields[6].split(\",\")))\n",
    "                    exon_ends = list(map(int, fields[7].split(\",\")))\n",
    "                except ValueError:\n",
    "                    print(f\"Skipping exon parsing issue at line {line_number}: {line.strip()}\")\n",
    "                    continue\n",
    "\n",
    "            transcript_key = f\"{chrom}:{start}-{end}\"\n",
    "            if transcript_key not in junctions:\n",
    "                junctions[transcript_key] = []\n",
    "\n",
    "            for exon_end, exon_start in zip(exon_ends, exon_starts):\n",
    "                junctions[transcript_key].append((exon_end, exon_start))\n",
    "    \n",
    "    return junctions\n",
    "\n",
    "def compute_global_codon_frequencies(sequences):\n",
    "    \"\"\"Computes a single set of codon frequencies across all exons in the dataset.\"\"\"\n",
    "    exon_sequence = \"\".join(sequences.values())\n",
    "    codons = [exon_sequence[i:i+3] for i in range(0, len(exon_sequence) - 2, 3) if len(exon_sequence[i:i+3]) == 3]\n",
    "    codon_counts = Counter(codons)\n",
    "    total_codons = sum(codon_counts.values())\n",
    "    \n",
    "    return {codon: count / total_codons for codon, count in codon_counts.items()} if total_codons > 0 else {}\n",
    "\n",
    "def generate_random_codon_sequence(length, global_codons, global_codon_weights):\n",
    "    \"\"\"Generates a shuffled exon sequence while preserving global codon frequencies.\"\"\"\n",
    "    num_codons = length // 3\n",
    "    shuffled_exon = ''.join(random.choices(global_codons, weights=global_codon_weights, k=num_codons))\n",
    "    \n",
    "    remainder = length % 3\n",
    "    if remainder > 0:\n",
    "        shuffled_exon += \"\".join(random.choices(\"ACGT\", k=remainder))\n",
    "    \n",
    "    return shuffled_exon\n",
    "\n",
    "def shuffle_sequences(canonical_sequences_file, output_file, junctions, global_codons, global_codon_weights):\n",
    "    with open(canonical_sequences_file, \"r\") as infile, open(output_file, \"w\") as outfile:\n",
    "        for line in infile:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue  # Skip empty lines\n",
    "\n",
    "            try:\n",
    "                header, sequence = line.split(\"\\t\")  # Extract header and sequence\n",
    "            except ValueError:\n",
    "                print(f\"Skipping malformed line: {line.strip()}\")\n",
    "                continue  # Skip improperly formatted lines\n",
    "\n",
    "            transcript_key = header  # e.g., \"chr1:934344-935477\"\n",
    "\n",
    "            if transcript_key in junctions:\n",
    "                exons_introns = []\n",
    "                last_pos = 0\n",
    "                for exon_end, exon_start in junctions[transcript_key]:\n",
    "                    exons_introns.append(sequence[last_pos:exon_end])  # Keep intron unchanged\n",
    "                    fake_exon = generate_random_codon_sequence(exon_start - exon_end, global_codons, global_codon_weights)\n",
    "                    exons_introns.append(fake_exon)\n",
    "                    last_pos = exon_start\n",
    "\n",
    "                exons_introns.append(sequence[last_pos:])  # Append final intron\n",
    "                shuffled_sequence = ''.join(exons_introns)\n",
    "            else:\n",
    "                shuffled_sequence = generate_random_codon_sequence(len(sequence), global_codons, global_codon_weights)\n",
    "\n",
    "            outfile.write(f\"{header}\\t{shuffled_sequence}\\n\")\n",
    "\n",
    "# File paths\n",
    "canonical_dataset_path = \"/mnt/lareaulab/sdahiyat/illumina/canonical_dataset_created.txt\"\n",
    "canonical_sequences_file = \"/mnt/lareaulab/sdahiyat/illumina/canonical_sequence_unflanked_unshuffled.txt\"\n",
    "output_file_path = \"/mnt/lareaulab/sdahiyat/illumina/shuffled_codons_2.txt\"\n",
    "\n",
    "# Parse junctions\n",
    "junctions = parse_junctions(canonical_dataset_path)\n",
    "\n",
    "# Compute global codon frequencies\n",
    "sequences_dict = {}\n",
    "with open(canonical_sequences_file, \"r\") as infile:\n",
    "    for line in infile:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            header, sequence = line.split(\"\\t\")\n",
    "            sequences_dict[header] = sequence\n",
    "        except ValueError:\n",
    "            print(f\"Skipping malformed line: {line}\")\n",
    "            continue\n",
    "\n",
    "global_codon_frequencies = compute_global_codon_frequencies(sequences_dict)\n",
    "global_codons = list(global_codon_frequencies.keys())\n",
    "global_codon_weights = list(global_codon_frequencies.values())\n",
    "\n",
    "shuffle_sequences(canonical_sequences_file, output_file_path, junctions, global_codons, global_codon_weights)\n",
    "\n",
    "print(f\"Shuffled sequences written to {output_file_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ddd6db8-a2f2-467d-aba5-446276560268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flanked sequences written to /mnt/lareaulab/sdahiyat/illumina/flanked_shuffled_codons_2.txt.\n"
     ]
    }
   ],
   "source": [
    "input_file = \"/mnt/lareaulab/sdahiyat/illumina/shuffled_codons_2.txt\"\n",
    "output_file = \"/mnt/lareaulab/sdahiyat/illumina/flanked_shuffled_codons_2.txt\"\n",
    "\n",
    "# Define the flanking sequence (5000 Ns)\n",
    "flank_length = 5000\n",
    "flanking_seq = \"N\" * flank_length\n",
    "\n",
    "with open(input_file, \"r\") as infile, open(output_file, \"w\") as outfile:\n",
    "    for line in infile:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  # Skip empty lines\n",
    "        \n",
    "        try:\n",
    "            header, sequence = line.split(\"\\t\")\n",
    "        except ValueError:\n",
    "            print(f\"Skipping malformed line: {line}\")\n",
    "            continue\n",
    "        \n",
    "        #extract chromosome, start, and end positions\n",
    "        if \":\" in header and \"-\" in header:\n",
    "            chrom, positions = header.split(\":\")\n",
    "            start, end = map(int, positions.split(\"-\"))\n",
    "            \n",
    "            #adjust start and end positions to reflect flanking\n",
    "            new_start = start - 5001 \n",
    "            new_end = end + 5000\n",
    "            \n",
    "            # make new header\n",
    "            new_header = f\"{chrom}:{new_start}-{new_end}\"\n",
    "            \n",
    "            # make new sequence with flanking Ns\n",
    "            flanked_sequence = flanking_seq + sequence + flanking_seq\n",
    "            
    "            outfile.write(f\"{new_header}\\t{flanked_sequence}\\n\")\n",
    "        else:\n",
    "            print(f\"Skipping improperly formatted header: {header}\")\n",
    "\n",
    "print(f\"Flanked sequences written to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c2d0d94-7d27-4f11-a062-740351dcaea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled sequences written to /mnt/lareaulab/sdahiyat/illumina/shuffled_codons_2.txt.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "def parse_junctions(file_path):\n",
    "    junctions = {}\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line_number, line in enumerate(f, start=1):\n",
    "            fields = line.strip().split(\"\\t\")\n",
    "            \n",
    "            if len(fields) < 6:\n",
    "                print(f\"Skipping invalid row at line {line_number}: {line.strip()}\")\n",
    "                continue\n",
    "            \n",
    "            chrom = fields[2]\n",
    "            try:\n",
    "                start = int(fields[4])\n",
    "                end = int(fields[5])\n",
    "            except ValueError:\n",
    "                print(f\"Skipping row with invalid start/end at line {line_number}: {line.strip()}\")\n",
    "                continue\n",
    "\n",
    "            exon_starts = []\n",
    "            exon_ends = []\n",
    "            if len(fields) >= 8:\n",
    "                try:\n",
    "                    exon_starts = list(map(int, fields[6].split(\",\")))\n",
    "                    exon_ends = list(map(int, fields[7].split(\",\")))\n",
    "                except ValueError:\n",
    "                    print(f\"Skipping exon parsing issue at line {line_number}: {line.strip()}\")\n",
    "                    continue\n",
    "\n",
    "            transcript_key = f\"{chrom}:{start}-{end}\"\n",
    "            if transcript_key not in junctions:\n",
    "                junctions[transcript_key] = []\n",
    "\n",
    "            for exon_end, exon_start in zip(exon_ends, exon_starts):\n",
    "                junctions[transcript_key].append((exon_end, exon_start))\n",
    "    \n",
    "    return junctions\n",
    "\n",
    "def compute_global_codon_frequencies(sequences):\n",
    "    \"\"\"Computes a single set of codon frequencies across all exons in the dataset.\"\"\"\n",
    "    exon_sequence = \"\".join(sequences.values())\n",
    "    codons = [exon_sequence[i:i+3] for i in range(0, len(exon_sequence) - 2, 3) if len(exon_sequence[i:i+3]) == 3]\n",
    "    codon_counts = Counter(codons)\n",
    "    total_codons = sum(codon_counts.values())\n",
    "    \n",
    "    return {codon: count / total_codons for codon, count in codon_counts.items()} if total_codons > 0 else {}\n",
    "\n",
    "def generate_random_codon_sequence(length, global_codons, global_codon_weights):\n",
    "    \"\"\"Generates a shuffled exon sequence while preserving global codon frequencies.\"\"\"\n",
    "    num_codons = length // 3\n",
    "    shuffled_exon = ''.join(random.choices(global_codons, weights=global_codon_weights, k=num_codons))\n",
    "    \n",
    "    remainder = length % 3\n",
    "    if remainder > 0:\n",
    "        shuffled_exon += \"\".join(random.choices(\"ACGT\", k=remainder))\n",
    "    \n",
    "    return shuffled_exon\n",
    "\n",
    "def shuffle_sequences(canonical_sequences_file, output_file, junctions, global_codons, global_codon_weights):\n",
    "    with open(canonical_sequences_file, \"r\") as infile, open(output_file, \"w\") as outfile:\n",
    "        for line in infile:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue  
    "            try:\n",
    "                header, sequence = line.split(\"\\t\")  
    "                print(f\"Skipping malformed line: {line.strip()}\")\n",
    "                continue  # Skip improperly formatted lines\n",
    "\n",
    "            transcript_key = header  # example: \"chr1:934344-935477\"\n",
    "\n",
    "            if transcript_key in junctions:\n",
    "                exons_introns = []\n",
    "                last_pos = 0\n",
    "                for exon_end, exon_start in junctions[transcript_key]:\n",
    "                    exons_introns.append(sequence[last_pos:exon_end])  # Keep intron unchanged\n",
    "                    fake_exon = generate_random_codon_sequence(exon_start - exon_end, global_codons, global_codon_weights)\n",
    "                    exons_introns.append(fake_exon)\n",
    "                    last_pos = exon_start\n",
    "\n",
    "                exons_introns.append(sequence[last_pos:])  # Append final intron\n",
    "                shuffled_sequence = ''.join(exons_introns)\n",
    "            else:\n",
    "                shuffled_sequence = generate_random_codon_sequence(len(sequence), global_codons, global_codon_weights)\n",
    "\n",
    "            outfile.write(f\"{header}\\t{shuffled_sequence}\\n\")\n",
    "\n",
    "canonical_dataset_path = \"/mnt/lareaulab/sdahiyat/illumina/canonical_dataset_created.txt\"\n",
    "canonical_sequences_file = \"/mnt/lareaulab/sdahiyat/illumina/canonical_sequence_unflanked_unshuffled.txt\"\n",
    "output_file_path = \"/mnt/lareaulab/sdahiyat/illumina/shuffled_codons_2.txt\"\n",
    "\n",
    "junctions = parse_junctions(canonical_dataset_path)\n",
    "\n",
    "sequences_dict = {}\n",
    "with open(canonical_sequences_file, \"r\") as infile:\n",
    "    for line in infile:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            header, sequence = line.split(\"\\t\")\n",
    "            sequences_dict[header] = sequence\n",
    "        except ValueError:\n",
    "            print(f\"Skipping malformed line: {line}\")\n",
    "            continue\n",
    "\n",
    "global_codon_frequencies = compute_global_codon_frequencies(sequences_dict)\n",
    "global_codons = list(global_codon_frequencies.keys())\n",
    "global_codon_weights = list(global_codon_frequencies.values())\n",
    "\n",
    "shuffle_sequences(canonical_sequences_file, output_file_path, junctions, global_codons, global_codon_weights)\n",
    "\n",
    "print(f\"Shuffled sequences written to {output_file_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba0a472a-ce8c-4dc9-84fa-89badf087b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flanked sequences written to /mnt/lareaulab/sdahiyat/illumina/flanked_shuffled_codons_2.txt.\n"
     ]
    }
   ],
   "source": [
    "input_file = \"/mnt/lareaulab/sdahiyat/illumina/shuffled_codons_2.txt\"\n",
    "output_file = \"/mnt/lareaulab/sdahiyat/illumina/flanked_shuffled_codons_2.txt\"\n",
    "\n",
    "flank_length = 5000\n",
    "flanking_seq = \"N\" * flank_length\n",
    "\n",
    "with open(input_file, \"r\") as infile, open(output_file, \"w\") as outfile:\n",
    "    for line in infile:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  #skip any empty lines\n",
    "        \n",
    "        try:\n",
    "            header, sequence = line.split(\"\\t\")\n",
    "        except ValueError:\n",
    "            print(f\"Skipping malformed line: {line}\")\n",
    "            continue\n",
    "        \n",
    "        #extracts chromosome, start, and end positions\n",
    "        if \":\" in header and \"-\" in header:\n",
    "            chrom, positions = header.split(\":\")\n",
    "            start, end = map(int, positions.split(\"-\"))\n",
    "            \n",
    "            # Adjust start and end positions\n",
    "            new_start = start - 5001 \n",
    "            new_end = end + 5000\n",
    "            \n",
    "            # Construct new header\n",
    "            new_header = f\"{chrom}:{new_start}-{new_end}\"\n",
    "            \n",
    "            # Construct new sequence with flanking Ns\n",
    "            flanked_sequence = flanking_seq + sequence + flanking_seq\n",
    "            \n",
    "            # Write to output file\n",
    "            outfile.write(f\"{new_header}\\t{flanked_sequence}\\n\")\n",
    "        else:\n",
    "            print(f\"Skipping improperly formatted header: {header}\")\n",
    "\n",
    "print(f\"Flanked sequences written to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "419a2ca0-9c8e-41d6-9726-6f09d207291a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total headers in /mnt/lareaulab/sdahiyat/illumina/flanked_shuffled_codons_2.txt: 19796\n",
      "Total headers in /mnt/lareaulab/sdahiyat/illumina/canonical_sequence_unflanked_unshuffled.txt: 19796\n"
     ]
    }
   ],
   "source": [
    "file1 = \"/mnt/lareaulab/sdahiyat/illumina/flanked_shuffled_codons_2.txt\"\n",
    "file2 = \"/mnt/lareaulab/sdahiyat/illumina/canonical_sequence_unflanked_unshuffled.txt\"\n",
    "\n",
    "def extract_headers(file_path):\n",
    "    headers = set()\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line.strip():  # Ignore empty lines\n",
    "                header = line.split(\"\\t\")[0]  # Extract header (before first tab)\n",
    "                headers.add(header)\n",
    "    return headers\n",
    "\n",
    "headers_file1 = extract_headers(file1)\n",
    "headers_file2 = extract_headers(file2)\n",
    "\n",
    "only_in_file1 = headers_file1 - headers_file2\n",
    "only_in_file2 = headers_file2 - headers_file1\n",
    "\n",
    "print(f\"Total headers in {file1}: {len(headers_file1)}\")\n",
    "print(f\"Total headers in {file2}: {len(headers_file2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b8a6d65-b779-4efb-9379-77285ec5fe37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled sequences written to /mnt/lareaulab/sdahiyat/illumina/shuffled_nt.txt.\n"
     ]
    }
   ],
   "source": [
    "nucleotide_frequencies = {\n",
    "    \"A\": 0.2781,\n",
    "    \"C\": 0.2025,\n",
    "    \"G\": 0.2120,\n",
    "    \"T\": 0.3075\n",
    "}\n",
    "nucleotides = list(nucleotide_frequencies.keys())\n",
    "weights = list(nucleotide_frequencies.values())\n",
    "\n",
    "def generate_random_sequence(length):\n",
    "    return ''.join(random.choices(nucleotides, weights=weights, k=length))\n",
    "\n",
    "def shuffle_sequences(canonical_sequences_file, output_file, junctions):\n",
    "    with open(canonical_sequences_file, \"r\") as infile, open(output_file, \"w\") as outfile:\n",
    "        for line in infile:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue  \n",
    "\n",
    "            try:\n",
    "                header, sequence = line.split(\"\\t\")  \n",
    "            except ValueError:\n",
    "                print(f\"Skipping malformed line: {line.strip()}\")\n",
    "                continue  \n",
    "\n",
    "            transcript_key = header  #chr1:934344-935477\n",
    "\n",
    "            if transcript_key in junctions:\n",
    "                exons_introns = []\n",
    "                last_pos = 0\n",
    "                for exon_end, exon_start in junctions[transcript_key]:\n",
    "                    \n",
    "                    exons_introns.append(sequence[last_pos:exon_end])\n",
    "\n",
    "                    \n",
    "                    exon_length = exon_start - exon_end\n",
    "                    fake_exon = generate_random_sequence(exon_length)\n",
    "                    exons_introns.append(fake_exon)\n",
    "\n",
    "                    last_pos = exon_start\n",
    "\n",
    "                \n",
    "                exons_introns.append(sequence[last_pos:])\n",
    "                shuffled_sequence = ''.join(exons_introns)\n",
    "            else:\n",
    "                \n",
    "                shuffled_sequence = generate_random_sequence(len(sequence))\n",
    "\n",
    "            outfile.write(f\"{header}\\t{shuffled_sequence}\\n\")\n",
    "\n",
    "canonical_dataset_path = \"/mnt/lareaulab/sdahiyat/illumina/canonical_dataset_created.txt\"\n",
    "canonical_sequences_file = \"/mnt/lareaulab/sdahiyat/illumina/canonical_sequence_unflanked_unshuffled.txt\"\n",
    "output_file_path = \"/mnt/lareaulab/sdahiyat/illumina/shuffled_nt.txt\"\n",
    "\n",
    "junctions = parse_junctions(canonical_dataset_path)\n",
    "\n",
    "shuffle_sequences(canonical_sequences_file, output_file_path, junctions)\n",
    "\n",
    "print(f\"Shuffled sequences written to {output_file_path}.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5fee18-98c2-4fd2-8d3c-085a9961c7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
