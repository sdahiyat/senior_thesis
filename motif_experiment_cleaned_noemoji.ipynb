{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9795f241",
   "metadata": {},
   "source": [
    "\n",
    "# Motif Shuffling Experiment - Dataset Preparation\n",
    "\n",
    "This notebook documents the steps taken to generate sequence datasets for evaluating how deep learning models (e.g., SpliceAI) rely on known RNA-binding protein (RBP) motifs, such as those bound by SR proteins.\n",
    "\n",
    "This process is part of a broader investigation into how well neural networks generalize splicing patterns when key regulatory signals are disrupted.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "- Detect and score RBP motifs using position weight matrices (PWMs)\n",
    "- Identify motif locations in exonic sequences\n",
    "- Select a subset of motifs for targeted shuffling\n",
    "- Generate new sequences with motif-disruptive shuffles while preserving all other genomic structure\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. **Load exon sequences and PWM matrix**\n",
    "2. **Score motifs using a sliding window**\n",
    "3. **Filter high-confidence motif matches**\n",
    "4. **Randomly shuffle selected motif regions**\n",
    "5. **Reconstruct the modified sequences**\n",
    "6. **Output shuffled FASTA and BED files**\n",
    "\n",
    "This notebook provides the core reproducible framework for generating input sequences used in the motif shuffle benchmarking experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503f12d5-98b0-4ac8-95e9-d4f33a8939ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "# PWM for SRSF1 (Matrix ID 126)\n",
    "pwm = {\n",
    "    'A': [0.00031, 0.00031, 0.49969, 0.49969, 0.00031, 0.00031, 0.99906],\n",
    "    'C': [0.99906, 0.49969, 0.49969, 0.49969, 0.49969, 0.49969, 0.00031],\n",
    "    'G': [0.00031, 0.49969, 0.00031, 0.00031, 0.49969, 0.49969, 0.00031],\n",
    "    'T': [0.00031, 0.00031, 0.00031, 0.00031, 0.00031, 0.00031, 0.00031],\n",
    "}\n",
    "\n",
    "motif_length = 7\n",
    "\n",
    "# Convert PWM to log-odds assuming uniform background (0.25)\n",
    "log_odds_pwm = {}\n",
    "for base in 'ACGT':\n",
    "    log_odds_pwm[base] = [math.log2(pwm[base][i] / 0.25) for i in range(motif_length)]\n",
    "\n",
    "\n",
    "def score_sequence(seq):\n",
    "    \"\"\"Calculate PWM score for a given sequence window.\"\"\"\n",
    "    score = 0\n",
    "    for i, base in enumerate(seq):\n",
    "        if base in log_odds_pwm:\n",
    "            score += log_odds_pwm[base][i]\n",
    "        else:\n",
    "            return None  # Skip sequences with ambiguous bases\n",
    "    return score\n",
    "\n",
    "\n",
    "def scan_sequence(seq, threshold):\n",
    "    \"\"\"Scan a sequence and return all motif hits with score >= threshold.\"\"\"\n",
    "    hits = []\n",
    "    for i in range(len(seq) - motif_length + 1):\n",
    "        window = seq[i:i + motif_length]\n",
    "        score = score_sequence(window)\n",
    "        if score is not None and score >= threshold:\n",
    "            hits.append((i, i + motif_length, score, window))\n",
    "    return hits\n",
    "\n",
    "\n",
    "def scan_fasta(input_file, output_file, threshold):\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                transcript_id, seq = line.split('\\t')\n",
    "            except ValueError:\n",
    "                print(f\"Skipping malformed line: {line}\")\n",
    "                continue\n",
    "            hits = scan_sequence(seq.upper(), threshold)\n",
    "            for start, end, score, window in hits:\n",
    "                outfile.write(f\"{transcript_id}\\t{start}\\t{end}\\t{score:.3f}\\t{window}\\n\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "scan_fasta(\n",
    "    input_file='/mnt/lareaulab/sdahiyat/illumina/canonical_sequence_unflanked_unshuffled.txt',\n",
    "    output_file='/mnt/lareaulab/sdahiyat/datasets/srsf1_motif_hits.tsv',\n",
    "    threshold=5.0  # Adjust this value depending on the score distribution\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caafbd35-5441-44f3-9d53-e870b0ee1e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_junctions(file_path):\n",
    "    junctions = {}\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            fields = line.strip().split(\"\\t\")\n",
    "            if len(fields) < 8:\n",
    "                continue\n",
    "            chrom = fields[2]\n",
    "            start = int(fields[4])\n",
    "            end = int(fields[5])\n",
    "            exon_starts = list(map(int, fields[6].split(\",\")))\n",
    "            exon_ends = list(map(int, fields[7].split(\",\")))\n",
    "            transcript_key = f\"{chrom}:{start}-{end}\"\n",
    "            junctions[transcript_key] = list(zip(exon_starts, exon_ends))\n",
    "    return junctions\n",
    "\n",
    "def extract_sequence(filepath, transcript_id):\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            tid, seq = line.strip().split(\"\\t\")\n",
    "            if tid == transcript_id:\n",
    "                return seq\n",
    "    return None\n",
    "\n",
    "# === Inputs ===\n",
    "transcript_id = \"chr1:65419-71585\"\n",
    "junction_file = \"/mnt/lareaulab/sdahiyat/illumina/canonical_dataset_created.txt\"\n",
    "unshuffled_file = \"/mnt/lareaulab/sdahiyat/illumina/motif_threshold_shuffled.txt\"\n",
    "\n",
    "# === Load data ===\n",
    "junctions = parse_junctions(junction_file)\n",
    "sequence = extract_sequence(unshuffled_file, transcript_id)\n",
    "\n",
    "# === Get introns ===\n",
    "seq_start = int(transcript_id.split(\":\")[1].split(\"-\")[0])\n",
    "exons = [(start - seq_start, end - seq_start) for start, end in junctions[transcript_id]]\n",
    "\n",
    "introns = []\n",
    "last = 0\n",
    "for start, end in exons:\n",
    "    if last < start:\n",
    "        introns.append(sequence[last:start])\n",
    "    last = end\n",
    "if last < len(sequence):\n",
    "    introns.append(sequence[last:])\n",
    "\n",
    "print(f\"ðŸ§¬ Transcript: {transcript_id} | Total introns: {len(introns)}\\n\")\n",
    "for i, intron in enumerate(introns, 1):\n",
    "    print(f\"Intron {i} (length {len(intron)}): {intron[:100]}{'...' if len(intron) > 100 else ''}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7efa0cd-00da-4277-808f-e5b6e28e821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"/mnt/lareaulab/sdahiyat/illumina/motif_threshold_shuffled.txt\"\n",
    "output_file = \"/mnt/lareaulab/sdahiyat/illumina/motif_threshold_shuffled_flanked.txt\"\n",
    "\n",
    "# Define the flanking sequence (5000 Ns)\n",
    "flank_length = 5000\n",
    "flanking_seq = \"N\" * flank_length\n",
    "\n",
    "with open(input_file, \"r\") as infile, open(output_file, \"w\") as outfile:\n",
    "    for line in infile:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  # Skip empty lines\n",
    "        \n",
    "        try:\n",
    "            header, sequence = line.split(\"\\t\")\n",
    "        except ValueError:\n",
    "            print(f\"Skipping malformed line: {line}\")\n",
    "            continue\n",
    "        \n",
    "        # Extract chromosome, start, and end positions\n",
    "        if \":\" in header and \"-\" in header:\n",
    "            chrom, positions = header.split(\":\")\n",
    "            start, end = map(int, positions.split(\"-\"))\n",
    "            \n",
    "            # Adjust start and end positions\n",
    "            new_start = start - 5001 \n",
    "            new_end = end + 5000\n",
    "            \n",
    "            # Construct new header\n",
    "            new_header = f\"{chrom}:{new_start}-{new_end}\"\n",
    "            \n",
    "            # Construct new sequence with flanking Ns\n",
    "            flanked_sequence = flanking_seq + sequence + flanking_seq\n",
    "            # Write to output file\n",
    "            outfile.write(f\"{new_header}\\t{flanked_sequence}\\n\")\n",
    "        else:\n",
    "            print(f\"Skipping improperly formatted header: {header}\")\n",
    "\n",
    "print(f\"Flanked sequences written to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21fa807-9caa-466e-b8c0-cb65dec772b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"/mnt/lareaulab/sdahiyat/datasets/srsf1_matches_shuffled.txt\"\n",
    "output_file = \"/mnt/lareaulab/sdahiyat/datasets/srsf1_matches_shuffled_flanked.txt\"\n",
    "\n",
    "# Define the flanking sequence (5000 Ns)\n",
    "flank_length = 5000\n",
    "flanking_seq = \"N\" * flank_length\n",
    "\n",
    "with open(input_file, \"r\") as infile, open(output_file, \"w\") as outfile:\n",
    "    for line in infile:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  # Skip empty lines\n",
    "        \n",
    "        try:\n",
    "            header, sequence = line.split(\"\\t\")\n",
    "        except ValueError:\n",
    "            print(f\"Skipping malformed line: {line}\")\n",
    "            continue\n",
    "        \n",
    "        # Extract chromosome, start, and end positions\n",
    "        if \":\" in header and \"-\" in header:\n",
    "            chrom, positions = header.split(\":\")\n",
    "            start, end = map(int, positions.split(\"-\"))\n",
    "            \n",
    "            # Adjust start and end positions\n",
    "            new_start = start - 5001 \n",
    "            new_end = end + 5000\n",
    "            \n",
    "            # Construct new header\n",
    "            new_header = f\"{chrom}:{new_start}-{new_end}\"\n",
    "            \n",
    "            # Construct new sequence with flanking Ns\n",
    "            flanked_sequence = flanking_seq + sequence + flanking_seq\n",
    "            # Write to output file\n",
    "            outfile.write(f\"{new_header}\\t{flanked_sequence}\\n\")\n",
    "        else:\n",
    "            print(f\"Skipping improperly formatted header: {header}\")\n",
    "\n",
    "print(f\"Flanked sequences written to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129d7523-35d9-492d-bd5d-c0d5835d0210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load keys from motif_matches_shuffled.txt\n",
    "motif_file = \"/mnt/lareaulab/sdahiyat/datasets/srsf1_matches_shuffled.txt\"\n",
    "motif_keys = set()\n",
    "\n",
    "with open(motif_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        key = line.split(\"\\t\")[0]  # e.g., \"chr1:65419-71585\"\n",
    "        motif_keys.add(key)\n",
    "\n",
    "# Step 2: Filter canonical_dataset_created.txt\n",
    "input_file = \"/mnt/lareaulab/sdahiyat/illumina/canonical_dataset_created.txt\"\n",
    "output_file = \"/mnt/lareaulab/sdahiyat/illumina/canonical_dataset_filtered_motifs.txt\"\n",
    "\n",
    "num_written = 0\n",
    "with open(input_file, \"r\") as infile, open(output_file, \"w\") as outfile:\n",
    "    for line in infile:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) < 6:\n",
    "            continue\n",
    "        chrom = parts[2]\n",
    "        try:\n",
    "            start = int(parts[4])\n",
    "            end = int(parts[5])\n",
    "        except ValueError:\n",
    "            continue\n",
    "        coord_key = f\"{chrom}:{start}-{end}\"\n",
    "        if coord_key in motif_keys:\n",
    "            outfile.write(line)\n",
    "            num_written += 1\n",
    "\n",
    "print(f\" Done! Wrote {num_written} matching entries to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b7890a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
